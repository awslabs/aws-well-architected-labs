---
AWSTemplateFormatVersion: '2010-09-09'
Description: Lambda to collect Org data and store in S3 
Parameters:
  DestinationBucket:
    Type: String
    Description: Name of the S3 Bucket that is created to hold org data
    AllowedPattern: (?=^.{3,63}$)(?!^(\d+\.)+\d+$)(^(([a-z0-9]|[a-z0-9][a-z0-9\-]*[a-z0-9])\.)*([a-z0-9]|[a-z0-9][a-z0-9\-]*[a-z0-9])$)
  Tags:
    Type: String
    Description: List of tags from your Organization you would like to include separated by a comma.
  ManagementAccountRole:
    Type: String
    Description:  ARN of the IAM role deployed in the management accounts which can retrieve lambda data.
  DatabaseName:
    Type: String
    Description: Athena Database name where you table will be created
    Default: managementcur
  GlueRoleARN:
    Type: String
  Suffix:
    Type: String
    Description: If this module needs to be made more than one a Suffix can be added
    Default: ''
  Schedule:
    Type: String
    Description: Cron job to trigger the lambda using cloudwatch event
    Default: "cron(30 12 L * ? *)"
Outputs:
  LambdaFunctionName:
    Value:
      Ref: LambdaOrgData
  LambdaFunctionARN:
    Description: Lambda function ARN.
    Value:
      Fn::GetAtt:
        - LambdaOrgData
        - Arn
Resources:
  LambdaOrgData:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: Lambda_Org_Data
      Description: LambdaFunctioni of python3.8.
      Runtime: python3.8
      Code:
        # S3Key: index.py.zip
        # S3Bucket: !Ref AWSCodeBucketName
        ZipFile: |
          #!/usr/bin/env python3
          #Gets org data, grouped by ous and tags from managment accounts in json
          #Author Stephanie Gooch 2020
          import argparse
          import boto3
          from botocore.exceptions import ClientError
          from botocore.client import Config
          import os
          import datetime
          import json

          def myconverter(o):
              if isinstance(o, datetime.datetime):
                  return o.__str__()

          def list_tags(client, resource_id):
              tags = []
              paginator = client.get_paginator("list_tags_for_resource")
              response_iterator = paginator.paginate(ResourceId=resource_id)
              for response in response_iterator:
                  tags.extend(response['Tags'])
              return tags
              
          def lambda_handler(event, context):
              management_role_arn = os.environ["MANAGMENTARN"]
              sts_connection = boto3.client('sts')
              acct_b = sts_connection.assume_role(
                  RoleArn=management_role_arn,
                  RoleSessionName="cross_acct_lambda"
              )
              ACCESS_KEY = acct_b['Credentials']['AccessKeyId']
              SECRET_KEY = acct_b['Credentials']['SecretAccessKey']
              SESSION_TOKEN = acct_b['Credentials']['SessionToken']
              client = boto3.client(
                  "organizations", region_name="us-east-1", #Using the Organizations client to get the data. This MUST be us-east-1 regardless of region you have the Lamda in
                  aws_access_key_id=ACCESS_KEY, aws_secret_access_key=SECRET_KEY, aws_session_token=SESSION_TOKEN,)

              root_id    = client.list_roots()['Roots'][0]['Id']
              ou_id_list = get_ou_ids(root_id, client)
              
              with open('/tmp/ou-org.json', 'w') as f:
                  for ou in ou_id_list.keys():
                      account_data(f, ou, ou_id_list[ou][0], client)
              s3_upload('ou-org')

              with open('/tmp/acc-org.json', 'w') as f:
                  account_data(f, root_id, root_id, client)
              s3_upload('acc-org')

          def account_data(f, parent, parent_name, client):
              tags_check = os.environ["TAGS"]
              account_id_list = get_acc_ids(parent, client)
              for account_id in account_id_list:
                  response = client.describe_account(AccountId=account_id)
                  account  = response["Account"]          
                  if tags_check != '':
                      tags_list = list_tags(client, account["Id"])
                      for tag in os.environ.get("TAGS").split(","):
                          for org_tag in tags_list:
                              if tag == org_tag['Key']: 
                                  value = org_tag['Value']
                                  kv = {tag : value}
                                  account.update(kv)
                  account.update({'Parent' : parent_name})        
                  data = json.dumps(account, default = myconverter) 

                  f.write(data)
                  f.write('\n')

          def s3_upload(file_name):
              bucket = os.environ["BUCKET_NAME"] 
              try:
                  s3 = boto3.client('s3', os.environ["REGION"],config=Config(s3={'addressing_style': 'path'}))
                  s3.upload_file(f'/tmp/{file_name}.json', bucket, f"organisation-data/{file_name}.json") 
                  print(f"{file_name}org data in s3")
              except Exception as e:
                  print(e)

          def ou_loop(parent_id, test, client):
            print(parent_id)
            paginator = client.get_paginator('list_children')
            iterator = paginator.paginate( ParentId=parent_id, ChildType='ORGANIZATIONAL_UNIT')
            for page in iterator:
                for ou in page['Children']:
                    test.append(ou['Id'])
                    ou_loop(ou['Id'], test, client)
            return test

          def get_ou_ids(parent_id, client):
              full_result = {}
              test = []
              ous = ou_loop(parent_id, test, client)
              print(ous)

              for ou in ous:
                  ou_info = client.describe_organizational_unit(OrganizationalUnitId=ou)
                  full_result[ou]=[]
                  full_result[ou].append(ou_info['OrganizationalUnit']['Name'])
              return full_result

          def get_acc_ids(parent_id,  client):
            full_result = []
            paginator = client.get_paginator('list_accounts_for_parent')
            iterator  = paginator.paginate(ParentId=parent_id)
            for page in iterator:
              for acc in page['Accounts']:
                print(acc['Id'])
                full_result.append(acc['Id'])
            return full_result
      Handler: 'index.lambda_handler'
      MemorySize: 2688
      Timeout: 300
      Role: 
        Fn::GetAtt:
          - LambdaRole
          - Arn
      Environment:
        Variables:
          TAGS:
            Fn::Sub: ${Tags}
          BUCKET_NAME: !Ref DestinationBucket
          REGION: !Ref "AWS::Region"
          MANAGMENTARN: !Ref ManagementAccountRole
  OrgCrawler:
    Type: AWS::Glue::Crawler
    Properties:
      Name: OrgGlueCrawler
      Role: !Ref GlueRoleARN
      DatabaseName: !Ref DatabaseName
      Schedule:
        ScheduleExpression: "cron(0 8 ? * MON *)"
      Targets:
        S3Targets:
          - Path: !Sub "s3://${DestinationBucket}/organisation-data/"
  LambdaRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Sub "AWS-Organization-Account-Collector-Role${Suffix}"
      AssumeRolePolicyDocument:
        Statement:
          - Action:
              - sts:AssumeRole
            Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
        Version: 2012-10-17
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/AWSLambdaExecute
      Path: /
      Policies:
        - PolicyName: "Assume-Management-Organization-Data-Role"
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: "Allow"
                Action: "sts:AssumeRole"
                Resource:
                  Ref: ManagementAccountRole
        - PolicyName: "S3-Access"
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: "Allow"
                Action:
                  - "logs:CreateLogGroup"
                  - "logs:CreateLogStream"
                  - "logs:PutLogEvents"
                  - "logs:DescribeLogStreams"
                Resource: "arn:aws:logs:*:*:*"
  CloudWatchTrigger:
    Type: AWS::Events::Rule
    Properties:
      Description: Monthly
      Name: !Sub "Monthly-Scheduler-For-Accounts${Suffix}"
      ScheduleExpression: !Ref Schedule
      State: ENABLED
      Targets:
        - Arn:
            Fn::GetAtt:
              - LambdaOrgData
              - Arn
          Id: WeeklyTriggerForGetAccounts
  EventPermission:
    Type: AWS::Lambda::Permission
    Properties:
      FunctionName: !GetAtt LambdaOrgData.Arn
      Action: lambda:InvokeFunction
      Principal: events.amazonaws.com
      SourceAccount: !Ref 'AWS::AccountId'
      SourceArn: !GetAtt CloudWatchTrigger.Arn